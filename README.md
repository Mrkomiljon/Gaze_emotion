# Gaze tracking | Emotion Estimation | Audio2text
## Usage
### Initial steps:
- Git clone this repository Run: `git clone https://github.com/manish-9245/Facial-Emotion-Recognition-using-OpenCV-and-Deepface.git`
- Run: `cd Facial-Emotion-Recognition-using-OpenCV-and-Deepface`
1. Install the required dependencies:
   - You can use `pip install -r requirements.txt`
   - Or you can install dependencies individually:
      - `pip install deepface`
      - `pip install tf_keras`
      - `pip install opencv-python`

2. Download the Haar cascade XML file for face detection:
   - Visit the [OpenCV GitHub repository](https://github.com/opencv/opencv/tree/master/data/haarcascades) and download the `haarcascade_frontalface_default.xml` file.

3. Run the code:
   - Execute the Python script.
   - The webcam will open, and real-time facial emotion detection will start.
   - Emotion labels will be displayed on the frames around detected faces.


<img width="1168" alt="emotion22" src="https://github.com/Mrkomiljon/Gaze_emotion/assets/92161283/be171374-9f01-4a15-991e-00c11974a1e9">
<img width="1075" alt="emotion23" src="https://github.com/Mrkomiljon/Gaze_emotion/assets/92161283/ded52574-3a1b-4798-83c4-8669c828e460">
